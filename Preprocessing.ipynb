{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd                                 #for data manipulation and analysis\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from gensim.models import Word2Vec                                   #For Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_train = pd.read_csv('./train/camera_train.csv',sep = '\\t')\n",
    "grocery_train = pd.read_csv('./train/grocery_train.csv',sep = '\\t')\n",
    "watches_train = pd.read_csv('./train/watches_train.csv',sep = '\\t')\n",
    "videogames_train = pd.read_csv('./train/videogames_train.csv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = pd.concat([camera_train,grocery_train,watches_train,videogames_train], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full train data for all four sets combined. \n",
    "Each category set remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camera</td>\n",
       "      <td>Works with a D610</td>\n",
       "      <td>Works well with my Nikon D610. The range is a ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camera</td>\n",
       "      <td>What a great bag! Tenba 637-262 Medium Shoulde...</td>\n",
       "      <td>Wow, construction of this bag is second to non...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Camera</td>\n",
       "      <td>i should have put system in a long time ago ...</td>\n",
       "      <td>i should have put system in a long time ago.  ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camera</td>\n",
       "      <td>9$? Way to good to be true but it is!</td>\n",
       "      <td>So, I'm new to the arca swiss world. And my bo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camera</td>\n",
       "      <td>Great camera, now if I can learn all its ...</td>\n",
       "      <td>Great camera, now if I can learn all its finer...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_category                                    review_headline  \\\n",
       "0           Camera                                  Works with a D610   \n",
       "1           Camera  What a great bag! Tenba 637-262 Medium Shoulde...   \n",
       "2           Camera    i should have put system in a long time ago ...   \n",
       "3           Camera              9$? Way to good to be true but it is!   \n",
       "4           Camera       Great camera, now if I can learn all its ...   \n",
       "\n",
       "                                         review_body sentiment_actual  \n",
       "0  Works well with my Nikon D610. The range is a ...              pos  \n",
       "1  Wow, construction of this bag is second to non...              pos  \n",
       "2  i should have put system in a long time ago.  ...              pos  \n",
       "3  So, I'm new to the arca swiss world. And my bo...              pos  \n",
       "4  Great camera, now if I can learn all its finer...              pos  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data = full_train_data[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "camera_train = camera_train[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "grocery_train = grocery_train[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "watches_train = watches_train[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "videogames_train = videogames_train[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "full_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword, punctuation removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emoticons = [\":-)\",\":)\",\":-]\",\":]\",\":-3\",\":3\",\":->\",\":>2\",\"8-)\",\"8)\",\":-}\",\":}\",\":o)\",\":c)\",\":^)\",\"=]\",\n",
    "                 \"=)\",\":-d\",\":d\",\"8-d\",\"8d\",\"x-d\",\"x-d\",\"xd\",\"=d\",\"=3\",\"b^d\",\":-))\",\";-)\",\";)\",\"*-)\",\n",
    "                 \"*)\",\";-]\",\";]\",\";^)\",\";d\",\":-p\",\":p\",\"x-p\",\":-?\",\":?\",\":-?\",\":?\",\":-b\",\n",
    "                 \":b\",\"=p\",\">:p\",\":*\",\":-*\",\"^.^\",\"^_^\",\"^-^\",\"xd\",\"<3\"]\n",
    "neg_emoticons = [\":-(\",\":(\",\":-c\",\":c\",\":-<\",\":<\",\":-[\",\":[\",\":-||\",\">:[\",\":{\",\":@\",\">:(\",\":-/\",\":/\",\">:\\\\\",\n",
    "                 \">:/\",\":\\\\\",\"=/\",\"=\\\\\",\":l\",\"=l\",\":S\",\":-|\",\":|\",\":-x\",\":x\",\"-.-\",\"-,-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = set(stopwords.words('english'))\n",
    "negations = [\"aren't\", \"aren\", \"couldn\", \"couldn't\", \"didn\", \"didn't\", \"doesn\", \"doesn't\", \"don\", \"don't\",\n",
    "                \"hadn\", \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\", \"isn\", \"isn't\", \"mightn\", \"mightn't\",\n",
    "                \"mustn\", \"mustn't\", \"needn\", \"needn't\", \"not\", \"shan\", \"shan't\", \"shouldn\", \"shouldn't\",\n",
    "                \"wasn\", \"wasn't\", \"weren\", \"weren't\", \"wouldn\", \"wouldn't\", \"won\", \"won't\"]\n",
    "for word in negations:\n",
    "    stopwordlist.remove(word)\n",
    "def isstopword(word):\n",
    "    '''checks whether word in stopwordlist'''\n",
    "    return word in stopwordlist\n",
    "\n",
    "def flipnegation(review):\n",
    "    '''unravels negated words'''\n",
    "    review = re.sub(r\"\\baren't\", \"are not\", review)\n",
    "    review = re.sub(r\"\\baren\", \"are not\", review)\n",
    "    review = re.sub(r\"\\bcouldn't\", \"could not\", review)\n",
    "    review = re.sub(r\"\\bcouldn\", \"could not\", review)\n",
    "    review = re.sub(r\"\\bdidn't\", \"did not\", review)\n",
    "    review = re.sub(r\"\\bdidn\", \"did not\", review)\n",
    "    review = re.sub(r\"\\bdoesn't\", \"does not\", review)\n",
    "    review = re.sub(r\"\\bdoesn\", \"does not\", review)\n",
    "    review = re.sub(r\"\\bdon't\", \"do not\", review)\n",
    "    review = re.sub(r\"\\bdon\", \"do not\", review)\n",
    "    review = re.sub(r\"\\bhadn't\", \"had not\", review)\n",
    "    review = re.sub(r\"\\bhadn\", \"had not\", review)\n",
    "    review = re.sub(r\"\\bhasn't\", \"has not\", review)\n",
    "    review = re.sub(r\"\\bhasn\", \"has not\", review)\n",
    "    review = re.sub(r\"\\bhaven't\", \"have not\", review)\n",
    "    review = re.sub(r\"\\bhaven\", \"have not\", review)\n",
    "    review = re.sub(r\"\\bisn't\", \"is not\", review)\n",
    "    review = re.sub(r\"\\bisn\", \"is not\", review)\n",
    "    review = re.sub(r\"\\bmightn't\", \"might not\", review)\n",
    "    review = re.sub(r\"\\bmightn\", \"might not\", review)\n",
    "    review = re.sub(r\"\\bmustn't\", \"must not\", review)\n",
    "    review = re.sub(r\"\\bmustn\", \"must not\", review)\n",
    "    review = re.sub(r\"\\bneedn't\", \"need not\", review)\n",
    "    review = re.sub(r\"\\bneedn\", \"need not\", review)\n",
    "    review = re.sub(r\"\\bshan't\", \"shall not\", review)\n",
    "    review = re.sub(r\"\\bshan\", \"shall not\", review)\n",
    "    review = re.sub(r\"\\bshouldn't\", \"should not\", review)\n",
    "    review = re.sub(r\"\\bshouldn\", \"should not\", review)\n",
    "    review = re.sub(r\"\\bwasn't\", \"was not\", review)\n",
    "    review = re.sub(r\"\\bwasn\", \"was not\", review)\n",
    "    review = re.sub(r\"\\bweren't\", \"were not\", review)\n",
    "    review = re.sub(r\"\\bweren\", \"were not\", review)\n",
    "    review = re.sub(r\"\\bwouldn't\", \"would not\", review)\n",
    "    review = re.sub(r\"\\bwouldn\", \"would not\", review)\n",
    "    review = re.sub(r\"\\bwon't\", \"will not\", review)\n",
    "    review = re.sub(r\"\\bwon\", \"will not\", review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    '''Preprocesses review applying tokenization, cleansing, stopword removal, emoticon handling, stemming etc.'''\n",
    "    processed_review = []\n",
    "  \n",
    "    review = str(review).lower() # set to lowercase\n",
    "    review = flipnegation(review) # unroll negations\n",
    "    review = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' link ', review) # replace hyperlinks with tag 'link'\n",
    "    review = re.sub(r'\\.{2,}', ' ', review) # replace multiple dots by whitespace\n",
    "    review = re.sub(r\"[!\\?\\.]i\", \"\", review) # clean some unproper sentence starts \n",
    "    review = re.sub(r'\\s+', ' ', review) # remove unnecessary whitespace\n",
    "    \n",
    "    tokens = review.split(\" \") # tokenize\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    for token in tokens:\n",
    "        if not isstopword(token):\n",
    "            token = token.strip(\"'\\”\")\n",
    "            if token in pos_emoticons:\n",
    "                token = \"pos_emoticon\"\n",
    "            elif token in neg_emoticons:\n",
    "                token = \"neg_emoticon\"\n",
    "            else:\n",
    "                token = re.sub(r\"[\\(\\)\\[\\]!\\?\\.\\-\\,]\", \"\", token) # remove punctuation/ parentheses \n",
    "                token = str(stemmer.stem(token))\n",
    "                \n",
    "            processed_review.append(token)\n",
    "\n",
    "    return ' '.join(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review needs to be processed in a lighter fashion so that terms match the pretrained embedding terms\n",
    "\n",
    "def process_review_light(review):\n",
    "    '''Preprocesses review in lighter fashion applying tokenization, cleansing, stopword removal'''\n",
    "    processed_review = []\n",
    "  \n",
    "    review = str(review).lower() # set to lowercase\n",
    "    review = flipnegation(review) # unroll negations\n",
    "    review = re.sub(r\"[!\\?\\.]i\", \"\", review) # clean some unproper sentence starts \n",
    "    review = re.sub(r'\\s+', ' ', review) # remove unnecessary whitespace\n",
    "    \n",
    "    tokens = review.split(\" \") # tokenize\n",
    "\n",
    "    for token in tokens:\n",
    "        if not isstopword(token):\n",
    "            token = token.strip(\"'\\”\")\n",
    "            token = re.sub(r\"[\\(\\)\\[\\]!\\?\\.\\-\\,]\", \"\", token) # remove punctuation/ parentheses    \n",
    "            processed_review.append(token)\n",
    "\n",
    "    return ' '.join(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data['processed'] = full_train_data['review_body'].apply(process_review)\n",
    "full_train_data['processed_light'] = full_train_data['review_body'].apply(process_review_light)\n",
    "\n",
    "full_train_data.to_csv('full_train_data.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment_actual</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camera</td>\n",
       "      <td>Works with a D610</td>\n",
       "      <td>Works well with my Nikon D610. The range is a ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>work well nikon d610 rang littl short though p...</td>\n",
       "      <td>works well nikon d610 range little short thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camera</td>\n",
       "      <td>What a great bag! Tenba 637-262 Medium Shoulde...</td>\n",
       "      <td>Wow, construction of this bag is second to non...</td>\n",
       "      <td>pos</td>\n",
       "      <td>wow construct bag second none plenti storag la...</td>\n",
       "      <td>wow construction bag second none plenty storag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Camera</td>\n",
       "      <td>i should have put system in a long time ago ...</td>\n",
       "      <td>i should have put system in a long time ago.  ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>put system long time ago pleas result instal p...</td>\n",
       "      <td>put system long time ago please results instal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camera</td>\n",
       "      <td>9$? Way to good to be true but it is!</td>\n",
       "      <td>So, I'm new to the arca swiss world. And my bo...</td>\n",
       "      <td>pos</td>\n",
       "      <td>so i'm new arca swiss world boss introduc real...</td>\n",
       "      <td>so i'm new arca swiss world boss introduced re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camera</td>\n",
       "      <td>Great camera, now if I can learn all its ...</td>\n",
       "      <td>Great camera, now if I can learn all its finer...</td>\n",
       "      <td>pos</td>\n",
       "      <td>great camera learn finer point turn one grands...</td>\n",
       "      <td>great camera learn finer points turns one gran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_category                                    review_headline  \\\n",
       "0           Camera                                  Works with a D610   \n",
       "1           Camera  What a great bag! Tenba 637-262 Medium Shoulde...   \n",
       "2           Camera    i should have put system in a long time ago ...   \n",
       "3           Camera              9$? Way to good to be true but it is!   \n",
       "4           Camera       Great camera, now if I can learn all its ...   \n",
       "\n",
       "                                         review_body sentiment_actual  \\\n",
       "0  Works well with my Nikon D610. The range is a ...              pos   \n",
       "1  Wow, construction of this bag is second to non...              pos   \n",
       "2  i should have put system in a long time ago.  ...              pos   \n",
       "3  So, I'm new to the arca swiss world. And my bo...              pos   \n",
       "4  Great camera, now if I can learn all its finer...              pos   \n",
       "\n",
       "                                           processed  \\\n",
       "0  work well nikon d610 rang littl short though p...   \n",
       "1  wow construct bag second none plenti storag la...   \n",
       "2  put system long time ago pleas result instal p...   \n",
       "3  so i'm new arca swiss world boss introduc real...   \n",
       "4  great camera learn finer point turn one grands...   \n",
       "\n",
       "                                     processed_light  \n",
       "0  works well nikon d610 range little short thoug...  \n",
       "1  wow construction bag second none plenty storag...  \n",
       "2  put system long time ago please results instal...  \n",
       "3  so i'm new arca swiss world boss introduced re...  \n",
       "4  great camera learn finer points turns one gran...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1712caeb841d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcamera_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review_body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_review\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcamera_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed_light'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review_body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_review_light\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcamera_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'camera_train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   2549\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2551\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-9c3b45327a7f>\u001b[0m in \u001b[0;36mprocess_review\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[\\(\\)\\[\\]!\\?\\.\\-\\,]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# remove punctuation/ parentheses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprocessed_review\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\stem\\snowball.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m   1539\u001b[0m         \u001b[1;31m# STEP 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msuffix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__step4_suffixes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1541\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1542\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ion\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera_train['processed'] = camera_train['review_body'].apply(process_review)\n",
    "camera_train['processed_light'] = camera_train['review_body'].apply(process_review_light)\n",
    "\n",
    "camera_train.to_csv('camera_train.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_train['processed'] = grocery_train['review_body'].apply(process_review)\n",
    "grocery_train['processed_light'] = grocery_train['review_body'].apply(process_review_light)\n",
    "\n",
    "grocery_train.to_csv('grocery_train.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "watches_train['processed'] = watches_train['review_body'].apply(process_review)\n",
    "watches_train['processed_light'] = watches_train['review_body'].apply(process_review_light)\n",
    "\n",
    "watches_train.to_csv('watches_train.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogames_train['processed'] = videogames_train['review_body'].apply(process_review)\n",
    "videogames_train['processed_light'] = videogames_train['review_body'].apply(process_review_light)\n",
    "\n",
    "videogames_train.to_csv('videogames_train.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_test = pd.read_csv('./test/camera_test.csv',sep = '\\t')\n",
    "grocery_test = pd.read_csv('./test/grocery_test.csv',sep = '\\t')\n",
    "watches_test = pd.read_csv('./test/watches_test.csv',sep = '\\t')\n",
    "videogames_test = pd.read_csv('./test/videogames_test.csv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = pd.concat([camera_test,grocery_test,watches_test,videogames_test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = full_test_data[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "camera_test = camera_test[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "grocery_test = grocery_test[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "watches_test = watches_test[['product_category','review_headline','review_body','sentiment_actual']]\n",
    "videogames_test = videogames_test[['product_category','review_headline','review_body','sentiment_actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data['processed'] = full_test_data['review_body'].apply(process_review)\n",
    "full_test_data['processed_light'] = full_test_data['review_body'].apply(process_review_light)\n",
    "\n",
    "full_test_data.to_csv('full_test_data.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_test['processed'] = camera_test['review_body'].apply(process_review)\n",
    "camera_test['processed_light'] = camera_test['review_body'].apply(process_review_light)\n",
    "\n",
    "camera_test.to_csv('camera_test.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_test['processed'] = grocery_test['review_body'].apply(process_review)\n",
    "grocery_test['processed_light'] = grocery_test['review_body'].apply(process_review_light)\n",
    "\n",
    "grocery_test.to_csv('grocery_test.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "watches_test['processed'] = watches_test['review_body'].apply(process_review)\n",
    "watches_test['processed_light'] = watches_test['review_body'].apply(process_review_light)\n",
    "\n",
    "watches_test.to_csv('watches_test.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogames_test['processed'] = videogames_test['review_body'].apply(process_review)\n",
    "videogames_test['processed_light'] = videogames_test['review_body'].apply(process_review_light)\n",
    "\n",
    "videogames_test.to_csv('videogames_test.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
